{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import openai\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the JSON dataset\n",
    "url = \"https://data.cdc.gov/resource/hfr9-rurv.json?$limit=285000\"\n",
    "\n",
    "# Fetch the JSON data\n",
    "response = requests.get(url)\n",
    "data_json = response.json()\n",
    "\n",
    "# Convert JSON data to DataFrame\n",
    "data = pd.json_normalize(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing target values\n",
    "data = data.dropna(subset=['data_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep a copy of the original 'question' column for later use\n",
    "questions = data['question'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['rowid', 'geolocation.type', 'geolocation.coordinates', 'data_value_unit', 'datavaluetypeid', 'data_value_type', 'data_value_footnote_symbol', 'data_value_footnote', 'classid', 'topicid', 'questionid', 'stratificationcategoryid1', 'stratificationid1', 'stratificationcategoryid2', 'stratificationid2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['locationabbr', 'locationdesc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['yearstart', 'yearend', 'datasource', 'class', 'topic', 'question',\n",
       "       'stratificationcategory1', 'stratification1', 'stratificationcategory2',\n",
       "       'stratification2', 'locationid', ':@computed_region_skr5_azej',\n",
       "       ':@computed_region_hjsp_umg2', 'data_value', 'data_value_alt',\n",
       "       'low_confidence_limit', 'high_confidence_limit'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "data_encoded = pd.get_dummies(data, columns=['datasource', 'class', 'topic', 'question', 'stratificationcategory1', 'stratification1', 'stratificationcategory2', 'stratification2'])\n",
    "\n",
    "# Normalize numerical columns\n",
    "scaler = StandardScaler()\n",
    "data_encoded[['yearstart', 'yearend', 'data_value']] = scaler.fit_transform(data_encoded[['yearstart', 'yearend', 'data_value']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = data_encoded.drop(columns=['data_value'])\n",
    "y = data_encoded['data_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns with non-numeric data\n",
    "non_numeric_columns = X_train.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode remaining non-numeric columns in the entire dataset\n",
    "X_train_encoded = pd.get_dummies(X_train, columns=non_numeric_columns)\n",
    "X_test_encoded = pd.get_dummies(X_test, columns=non_numeric_columns)\n",
    "\n",
    "# Ensure both train and test sets have the same columns after one-hot encoding\n",
    "X_train_blm, X_test_blm = X_train_encoded.align(X_test_encoded, join='left', axis=1, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['baseline_model_no_geo.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train the baseline model\n",
    "baseline_model = RandomForestRegressor(random_state=42)\n",
    "baseline_model.fit(X_train_blm, y_train)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(baseline_model, 'baseline_model_no_geo.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = baseline_model.predict(X_test_blm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model MSE (no geolocation): 0.023929710661168356\n",
      "Baseline Model MAE (no geolocation): 0.08680289587763589\n",
      "Baseline Model R-squared (no geolocation): 0.9761880389063137\n",
      "Baseline Model EVS (no geolocation): 0.9761880393042391\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the baseline model\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "baseline_mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Baseline Model MSE (no geolocation): {baseline_mse}')\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "baseline_mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'Baseline Model MAE (no geolocation): {baseline_mae}')\n",
    "\n",
    "# R-squared (Coefficient of Determination)\n",
    "baseline_r2 = r2_score(y_test, y_pred)\n",
    "print(f'Baseline Model R-squared (no geolocation): {baseline_r2}')\n",
    "\n",
    "# Explained Variance Score\n",
    "baseline_evs = explained_variance_score(y_test, y_pred)\n",
    "print(f'Baseline Model EVS (no geolocation): {baseline_evs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text data\n",
    "text_data = data['question'].values\n",
    "inputs = tokenizer(text_data.tolist(), return_tensors='pt', padding=True, truncation=True, max_length=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate BERT embeddings in batches\n",
    "def generate_bert_embeddings_in_batches(model, tokenizer, texts, batch_size=32):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        inputs = tokenizer(batch_texts.tolist(), return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            batch_embeddings = outputs.last_hidden_state[:, 0, :].numpy()  # [CLS] token representation\n",
    "            embeddings.append(batch_embeddings)\n",
    "    return np.vstack(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate BERT embeddings in batches\n",
    "bert_embeddings = generate_bert_embeddings_in_batches(bert_model, tokenizer, text_data, batch_size=32)\n",
    "\n",
    "np.save('bert_embeddings_no_geo.npy', bert_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add BERT embeddings to the numerical and categorical features\n",
    "X_combined = np.hstack((X.values, bert_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the combined data into training and testing sets\n",
    "X_train_combined, X_test_combined, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the model\n",
    "model_with_bert = RandomForestRegressor(random_state=42)\n",
    "model_with_bert.fit(X_train_combined, y_train)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model_with_bert, 'model_with_bert_no_geo.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred_with_bert = model_with_bert.predict(X_test_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "bert_mse = mean_squared_error(y_test, y_pred_with_bert)\n",
    "print(f'BERT Model MSE (no geolocation): {bert_mse}')\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "bert_mae = mean_absolute_error(y_test, y_pred_with_bert)\n",
    "print(f'BERT Model MAE (no geolocation): {bert_mae}')\n",
    "\n",
    "# R-squared (Coefficient of Determination)\n",
    "bert_r2 = r2_score(y_test, y_pred_with_bert)\n",
    "print(f'BERT Model R-squared (no geolocation): {bert_r2}')\n",
    "\n",
    "# Explained Variance Score\n",
    "bert_evs = explained_variance_score(y_test, y_pred_with_bert)\n",
    "print(f'BERT Model EVS (no geolocation): {bert_evs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate embeddings using GPT-4\n",
    "def get_gpt4_embeddings(text):\n",
    "    response = openai.embeddings.create(\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        input=text\n",
    "    )\n",
    "    return response.data[0].embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply GPT-4 embeddings to relevant text columns\n",
    "data['gpt4_embedding'] = data.apply(\n",
    "    lambda row: get_gpt4_embeddings(\n",
    "        f\"{row['question']} {row['class']} {row['topic']} {row['stratification1']} {row['stratification2']}\"\n",
    "    ), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of embeddings to a numpy array for model input\n",
    "gpt4_embeddings = np.array(data['gpt4_embedding'].tolist())\n",
    "\n",
    "np.save('gpt4_embeddings_no_geo.npy', gpt4_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add GPT-4 embeddings to the numerical and categorical features\n",
    "X_gpt4 = np.hstack((X.values, gpt4_embeddings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-split the data into training and testing sets\n",
    "X_train_gpt4, X_test_gpt4, y_train, y_test = train_test_split(X_gpt4, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_with_gpt4_no_geo.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train the RandomForestRegressor with GPT-4 embeddings\n",
    "model_with_gpt4 = RandomForestRegressor(random_state=42)\n",
    "model_with_gpt4.fit(X_train_gpt4, y_train)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model_with_gpt4, 'model_with_gpt4_no_geo.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred_with_gpt4 = model_with_gpt4.predict(X_test_gpt4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4 Model MSE (no geolocation): 1.1409982786002147e-09\n",
      "GPT-4 Model MAE (no geolocation): 6.387050115009729e-07\n",
      "GPT-4 Model R-squared (no geolocation): 0.999999998865823\n",
      "GPT-4 Model EVS (no geolocation): 0.999999998865836\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "# Mean Squared Error (MSE)\n",
    "gpt4_mse = mean_squared_error(y_test, y_pred_with_gpt4)\n",
    "print(f'GPT-4 Model MSE (no geolocation): {gpt4_mse}')\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "gpt4_mae = mean_absolute_error(y_test, y_pred_with_gpt4)\n",
    "print(f'GPT-4 Model MAE (no geolocation): {gpt4_mae}')\n",
    "\n",
    "# R-squared (Coefficient of Determination)\n",
    "gpt4_r2 = r2_score(y_test, y_pred_with_gpt4)\n",
    "print(f'GPT-4 Model R-squared (no geolocation): {gpt4_r2}')\n",
    "\n",
    "# Explained Variance Score\n",
    "gpt4_evs = explained_variance_score(y_test, y_pred_with_gpt4)\n",
    "print(f'GPT-4 Model EVS (no geolocation): {gpt4_evs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
